# ğŸš€ **Complete Workflow Pipeline for GCP Deployment & Model Training Using Kubeflow Pipelines**  

## ğŸ“Œ **Project Overview**  
This project provides a **complete workflow pipeline** for deploying and training a machine learning model on **Google Cloud Platform (GCP)** using **Kubeflow Pipelines**. The entire process is detailed in the **Jupyter Notebook(code.ipynb)**, serving as a guided walkthrough for setting up, training, and deploying models efficiently on the cloud.  

## ğŸ” **Key Features**  
- **GCP Setup Guide** â€“ Instructions for account setup, billing configuration, and project initialization.  
- **Kubeflow Pipeline Implementation** â€“ A step-by-step breakdown of building and executing **Kubeflow Pipelines** for model training and deployment.  
- **End-to-End Machine Learning Workflow** â€“ Covers **data preprocessing, model training, hyperparameter tuning, evaluation, and deployment** on GCP.  
- **Integration with Cloud Services** â€“ Utilizes **Cloud Storage, Vertex AI, and Kubernetes Engine** to streamline the ML pipeline.  

## ğŸ—ï¸ **Workflow Pipeline Breakdown**  
1ï¸âƒ£ **Google Cloud Platform (GCP) Setup**  
   - Creating a **GCP account** and enabling necessary services.  
   - Setting up a **billing account** and configuring IAM roles.  

2ï¸âƒ£ **Kubeflow Pipelines Configuration**  
   - Installing **Kubeflow Pipelines**.  
   - Setting up pipeline components, including data ingestion, transformation, and model training.  

3ï¸âƒ£ **Model Training & Hyperparameter Tuning**  
   - Training a machine learning model using **PyTorch**.  
  

4ï¸âƒ£ **Model Evaluation & Deployment**  
   - Evaluating model performance using **metrics and validation techniques**.  
   - Deploying the trained model using **Vertex AI** and **Kubeflow Serving**.  

5ï¸âƒ£ **Automating the Workflow with Kubeflow Pipelines**  
   - Creating pipeline components using **Python SDK**.  
   - Executing end-to-end **MLOps workflow automation**.  

## âš™ï¸ **Setup & Execution**  
### 1ï¸âƒ£ Prerequisites  
- Complete detailed mention in 
- **Google Cloud SDK** installed & authenticated  
- **Kubeflow Pipelines** configured  
- **Docker CLI** installed  

### 2ï¸âƒ£ Running the Notebook  
- Clone the repository:
  ```bash
  git clone <repo_url>
  cd <repo_directory>
  ```
- Install required dependencies:
  ```bash
  pip install -r requirements.txt
  ```
- Launch Jupyter Notebook:
  ```bash
  jupyter notebook code.ipynb
  ```
- Follow the notebook steps for execution.  

## ğŸ† **Why Use This Pipeline?**  
âœ”ï¸ **Scalable & Reproducible** â€“ Automates ML training & deployment.  
âœ”ï¸ **Cloud-Native** â€“ Utilizes GCP services for high performance.  
âœ”ï¸ **Customizable** â€“ Modify pipeline steps for different ML use cases.  

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ“¬ Contact

For any questions or collaboration opportunities, reach out at:
ğŸ“§ [Email](akshatvaja1303@gmail.com) | ğŸ’¬ LinkedIn: [Akshat Vaja](https://www.linkedin.com/in/akshat-vaja/)